{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **EDA + Logistic Regression + PCA**\n",
    "\n",
    "\n",
    "Hello friends,\n",
    "\n",
    "This kernel is all about **Principal Component Analysis** - a **Dimensionality Reduction** technique.\n",
    "\n",
    "I have used the **adult** data set for this kernel. This dataset is very small for PCA purpose. My main purpose is to demonstrate PCA implementation with this dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "The contents of this kernel is divided into various topics which are as follows:-\n",
    "\n",
    "-   The Curse of Dimensionality\n",
    "-\tIntroduction to Principal Component Analysis\n",
    "-\tImport Python libraries\n",
    "-\tImport dataset\n",
    "-\tExploratory data analysis\n",
    "-\tSplit data into training and test set\n",
    "-\tFeature engineering\n",
    "-\tFeature scaling\n",
    "-\tLogistic regression model with all features\n",
    "-\tLogistic Regression with PCA\n",
    "-\tSelect right number of dimensions\n",
    "-\tPlot explained variance ratio with number of dimensions\n",
    "-\tConclusion\n",
    "-\tReferences\n",
    "\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Curse of Dimensionality\n",
    "\n",
    "Generally, real world datasets contain thousands or millions of features to train for. This is very time consuming task as this makes training extremely slow. In such cases, it is very difficult to find a good solution. This problem is often referred to as the curse of dimensionality.\n",
    "\n",
    "\n",
    "The **curse of dimensionality** happens when we work with data that has many features (dimensions). As the number of dimensions increases, the space grows so fast that the data becomes very spread out. This makes it hard to get meaningful results.\n",
    "\n",
    "To solve this, we can often reduce the number of dimensions. This is called **dimensionality reduction**. It means keeping only the most important features. This makes training faster and helps with visualizing the data.\n",
    "\n",
    "The most popular dimensionality reduction technique is Principal Component Analysis (PCA), which is discussed below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Principal Component Analysis (PCA)\n",
    "\n",
    "\n",
    "**Principal Component Analysis (PCA)** is a dimensionality reduction technique that can be used to reduce a larger set of feature variables into a smaller set that still contains most of the variance in the larger set. \n",
    "\n",
    "### Preserve the variance\n",
    "\n",
    "PCA, first identifies the hyperplane that lies closest to the data and then it projects the data onto it. Before, we can project the training set onto a lower-dimensional hyperplane, we need to select the right hyperplane. The projection can be done in such a way so as to preserve the maximum variance. This is the idea behind PCA.\n",
    "\n",
    "### Principal Components\n",
    "\n",
    "PCA identifies the axes that accounts for the maximum amount of cumulative sum of variance in the training set **PCA finds the axes that capture the most overall variation in the training data**. These are called Principal Components. PCA assumes that the dataset is centered around the origin. Scikit-Learnâ€™s PCA classes take care of centering the data automatically.\n",
    "\n",
    "### Projecting down to d Dimensions\n",
    "\n",
    "Once, we have identified all the principal components, we can reduce the dimensionality of the dataset down to d dimensions by projecting it onto the hyperplane defined by the first d principal components. This ensures that the projection will preserve as much variance as possible.\n",
    "\n",
    "\n",
    "\n",
    "Now, let's get to the implementation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "# import libraries for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "\n",
    "# Working with os module - os is a module in Python 3.\n",
    "# Its main purpose is to interact with the operating system. \n",
    "# It provides functionalities to manipulate files and folders.\n",
    "\n",
    "#import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "#print('# File sizes')\n",
    "#for f in os.listdir('../input'):\n",
    "    #print(f.ljust(30) + str(round(os.path.getsize('../input/' + f) / 1000000, 2)) + 'MB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 78.1 ms\n",
      "Wall time: 88.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv(r'D:\\nit_prac\\ðŸ“…july\\3rd july - knn\\knn\\projects\\LOGISTIC REGRESSION , PCA, EDA\\adult\\adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check shape of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are 32561 instances and 15 attributes in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preview dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View summary of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Summary of the dataset shows that there are no missing values. But the preview shows that the dataset contains values coded as `?`. So, I will encode `?` as NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode `?` as `NaNs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df == '?'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Again check the summary of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       30725 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      30718 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  31978 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the summary shows that the variables - `workclass`, `occupation` and `native.country` contain missing values. All of these variables are categorical data type. So, I will impute the missing values with the most frequent value- the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['workclass', 'occupation', 'native.country']:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)    \n",
    "    \n",
    "#  Sometimes, there can be more than one mode â€” for example, if two or more values appear equally often. Using [0] selects the first mode from that Series.\n",
    "#  inplace=True is a convenient way to update the DataFrame in place without having to reassign the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check again for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education.num     0\n",
       "marital.status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital.gain      0\n",
       "capital.loss      0\n",
       "hours.per.week    0\n",
       "native.country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that there are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting feature vector and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['income'], axis=1)\n",
    "\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>Private</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>Private</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90   Private   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66   Private  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0     Prof-specialty  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2     Prof-specialty      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country  \n",
       "0          4356              40  United-States  \n",
       "1          4356              18  United-States  \n",
       "2          4356              40  United-States  \n",
       "3          3900              40  United-States  \n",
       "4          3900              40  United-States  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into separate training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "categorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        X_train[feature] = le.fit_transform(X_train[feature])\n",
    "        X_test[feature] = le.transform(X_test[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101484</td>\n",
       "      <td>2.600478</td>\n",
       "      <td>-1.494279</td>\n",
       "      <td>-0.332263</td>\n",
       "      <td>1.133894</td>\n",
       "      <td>-0.402341</td>\n",
       "      <td>-0.782234</td>\n",
       "      <td>2.214196</td>\n",
       "      <td>0.39298</td>\n",
       "      <td>-1.430470</td>\n",
       "      <td>-0.145189</td>\n",
       "      <td>-0.217407</td>\n",
       "      <td>-1.662414</td>\n",
       "      <td>0.262317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028248</td>\n",
       "      <td>-1.884720</td>\n",
       "      <td>0.438778</td>\n",
       "      <td>0.184396</td>\n",
       "      <td>-0.423425</td>\n",
       "      <td>-0.402341</td>\n",
       "      <td>-0.026696</td>\n",
       "      <td>-0.899410</td>\n",
       "      <td>0.39298</td>\n",
       "      <td>0.699071</td>\n",
       "      <td>-0.145189</td>\n",
       "      <td>-0.217407</td>\n",
       "      <td>-0.200753</td>\n",
       "      <td>0.262317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.247956</td>\n",
       "      <td>-0.090641</td>\n",
       "      <td>0.045292</td>\n",
       "      <td>1.217715</td>\n",
       "      <td>-0.034095</td>\n",
       "      <td>0.926666</td>\n",
       "      <td>-0.782234</td>\n",
       "      <td>-0.276689</td>\n",
       "      <td>0.39298</td>\n",
       "      <td>-1.430470</td>\n",
       "      <td>-0.145189</td>\n",
       "      <td>-0.217407</td>\n",
       "      <td>-0.038346</td>\n",
       "      <td>0.262317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.850587</td>\n",
       "      <td>-1.884720</td>\n",
       "      <td>0.793152</td>\n",
       "      <td>0.184396</td>\n",
       "      <td>-0.423425</td>\n",
       "      <td>0.926666</td>\n",
       "      <td>-0.530388</td>\n",
       "      <td>0.968753</td>\n",
       "      <td>0.39298</td>\n",
       "      <td>0.699071</td>\n",
       "      <td>-0.145189</td>\n",
       "      <td>-0.217407</td>\n",
       "      <td>-0.038346</td>\n",
       "      <td>0.262317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.044989</td>\n",
       "      <td>-2.781760</td>\n",
       "      <td>-0.853275</td>\n",
       "      <td>0.442726</td>\n",
       "      <td>1.523223</td>\n",
       "      <td>-0.402341</td>\n",
       "      <td>-0.782234</td>\n",
       "      <td>-0.899410</td>\n",
       "      <td>0.39298</td>\n",
       "      <td>0.699071</td>\n",
       "      <td>-0.145189</td>\n",
       "      <td>-0.217407</td>\n",
       "      <td>-0.038346</td>\n",
       "      <td>0.262317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0  0.101484   2.600478 -1.494279  -0.332263       1.133894       -0.402341   \n",
       "1  0.028248  -1.884720  0.438778   0.184396      -0.423425       -0.402341   \n",
       "2  0.247956  -0.090641  0.045292   1.217715      -0.034095        0.926666   \n",
       "3 -0.850587  -1.884720  0.793152   0.184396      -0.423425        0.926666   \n",
       "4 -0.044989  -2.781760 -0.853275   0.442726       1.523223       -0.402341   \n",
       "\n",
       "   occupation  relationship     race       sex  capital.gain  capital.loss  \\\n",
       "0   -0.782234      2.214196  0.39298 -1.430470     -0.145189     -0.217407   \n",
       "1   -0.026696     -0.899410  0.39298  0.699071     -0.145189     -0.217407   \n",
       "2   -0.782234     -0.276689  0.39298 -1.430470     -0.145189     -0.217407   \n",
       "3   -0.530388      0.968753  0.39298  0.699071     -0.145189     -0.217407   \n",
       "4   -0.782234     -0.899410  0.39298  0.699071     -0.145189     -0.217407   \n",
       "\n",
       "   hours.per.week  native.country  \n",
       "0       -1.662414        0.262317  \n",
       "1       -0.200753        0.262317  \n",
       "2       -0.038346        0.262317  \n",
       "3       -0.038346        0.262317  \n",
       "4       -0.038346        0.262317  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score with all the features: 0.8218\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with all the features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with PCA\n",
    "\n",
    "Scikit-Learn's PCA class implements PCA algorithm using the code below. Before diving deep, I will explain another important concept called explained variance ratio.\n",
    "\n",
    "\n",
    "### Explained Variance Ratio\n",
    "\n",
    "A very useful piece of information is the **explained variance ratio** of each principal component. It is available via the `explained_variance_ratio_ ` variable. It indicates the proportion of the datasetâ€™s variance that lies along the axis of each principal component.\n",
    "\n",
    "Now, let's get to the PCA implementation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14757168, 0.10182915, 0.08147199, 0.07880174, 0.07463545,\n",
       "       0.07274281, 0.07009602, 0.06750902, 0.0647268 , 0.06131155,\n",
       "       0.06084207, 0.04839584, 0.04265038, 0.02741548])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "pca.explained_variance_ratio_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- We can see that approximately 97.25% of variance is explained by the first 13 variables. \n",
    "\n",
    "- Only 2.75% of variance is explained by the last variable. So, we can assume that it carries little information. \n",
    "\n",
    "- So, I will drop it, train the model again and calculate the accuracy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with first 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score with the first 13 features: 0.8213\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['income','native.country'], axis=1)\n",
    "y = df['income']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "categorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        X_train[feature] = le.fit_transform(X_train[feature])\n",
    "        X_test[feature] = le.transform(X_test[feature])\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with the first 13 features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- We can see that accuracy has been decreased from 0.8218 to 0.8213 after dropping the last feature.\n",
    "\n",
    "- Now, if I take the last two features combined, then we can see that approximately 7% of variance is explained by them.\n",
    "\n",
    "- I will drop them, train the model again and calculate the accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with first 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score with the first 12 features: 0.8227\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['income','native.country', 'hours.per.week'], axis=1)\n",
    "y = df['income']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "categorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        X_train[feature] = le.fit_transform(X_train[feature])\n",
    "        X_test[feature] = le.transform(X_test[feature])\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with the first 12 features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- Now, it can be seen that the accuracy has been increased to 0.8227, if the model is trained with 12 features.\n",
    "\n",
    "- Lastly, I will take the last three features combined. Approximately 11.83% of variance is explained by them.\n",
    "\n",
    "- I will repeat the process, drop these features, train the model again and calculate the accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression with first 11 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score with the first 11 features: 0.8186\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['income','native.country', 'hours.per.week', 'capital.loss'], axis=1)\n",
    "y = df['income']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "categorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        X_train[feature] = le.fit_transform(X_train[feature])\n",
    "        X_test[feature] = le.transform(X_test[feature])\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
    "\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with the first 11 features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- We can see that accuracy has significantly decreased to 0.8187 if I drop the last three features.\n",
    "\n",
    "- Our aim is to maximize the accuracy. We get maximum accuracy with the first 12 features and the accuracy is 0.8227."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select right number of dimensions\n",
    "\n",
    "- The above process works well if the number of dimensions are small.\n",
    "\n",
    "- But, it is quite cumbersome if we have large number of dimensions.\n",
    "\n",
    "- In that case, a better approach is to compute the number of dimensions that can explain significantly large portion of the variance.\n",
    "\n",
    "- The following code computes PCA without reducing dimensionality, then computes the minimum number of dimensions required to preserve 90% of the training set variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of dimensions required to preserve 90% of variance is 12\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['income'], axis=1)\n",
    "y = df['income']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "\n",
    "categorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n",
    "for feature in categorical:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        X_train[feature] = le.fit_transform(X_train[feature])\n",
    "        X_test[feature] = le.transform(X_test[feature])\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n",
    "\n",
    "\n",
    "pca= PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "dim = np.argmax(cumsum >= 0.90) + 1\n",
    "print('The number of dimensions required to preserve 90% of variance is',dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- With the required number of dimensions found, we can then set number of dimensions to `dim` and run PCA again.\n",
    "\n",
    "- With the number of dimensions set to `dim`, we can then calculate the required accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot explained variance ratio with number of dimensions\n",
    "\n",
    "- An alternative option is to plot the explained variance as a function of the number of dimensions.\n",
    "\n",
    "- In the plot, we should look for an elbow where the explained variance stops growing fast.\n",
    "\n",
    "- This can be thought of as the intrinsic dimensionality of the dataset.\n",
    "\n",
    "- Now, I will plot cumulative explained variance ratio with number of components to show how variance ratio varies with number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "The above plot shows that almost 90% of variance is explained by the first 12 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "-\tIn this kernel, I have discussed Principal Component Analysis â€“ the most popular dimensionality reduction technique.\n",
    "-\tI have demonstrated PCA implementation with Logistic Regression on the adult dataset.\n",
    "-\tI found the maximum accuracy with the first 12 features and it is found to be 0.8227.\n",
    "-\tAs expected, the number of dimensions required to preserve 90 % of variance is found to be 12.\n",
    "-\tFinally, I plot the explained variance ratio with number of dimensions. The graph confirms that approximately 90% of variance is explained by the first 12 components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "The ideas and concepts in this kernel are taken from the following book.\n",
    "\n",
    "- Hands on Machine Learning with Scikit-Learn and Tensorflow by Aurelien Geron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
